{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_first\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.initializers import Constant\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dense, Flatten, Add, Concatenate\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Lambda, UpSampling2D\n",
    "from keras.layers import ReLU, LeakyReLU, PReLU\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "import keras.backend as K\n",
    "print(K.image_data_format())\n",
    "K.set_learning_phase(1) #for batchnorm\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "#torch.backends.cudnn.enabled = True\n",
    "\n",
    "def tt(x):\n",
    "    return torch.tensor(x).float()\n",
    "\n",
    "def npa(x):\n",
    "    return x.detach().numpy()\n",
    "\n",
    "# Generate pictures with different lights to verify that pmodel.Train(True) is actually relighting\n",
    "# and always looks better. Check how to reproduce pmodel.Train(False) in keras.\n",
    "\n",
    "# Save keras model as single file and test loading it.\n",
    "# Compare speeds of keras and pytorch.\n",
    "# Generate animation?\n",
    "\n",
    "# pytorch is channels_first. now keras too (keras config).\n",
    "# In keras batch normalization, use axis=1 if channels_first.\n",
    "# Keras batchnorm: K.set_learning_phase(1)\n",
    "# Pytorch batchnorm: don't use model.train(False)\n",
    "\n",
    "# The pytorch network specifies values for mean and variance in some batchnorms, but I didn't translate them to Keras because they don't seem to produce any change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "#                                center=True, scale=True, beta_initializer='zeros',\n",
    "#                                gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                moving_variance_initializer='ones', beta_regularizer=None,\n",
    "#                                gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "#nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#bnopt = {'momentum':0.1, 'scale':False, 'moving_mean_initializer':Constant(value=0.5),'moving_variance_initializer':Constant(value=0.25)}\n",
    "\n",
    "bnopt = {\n",
    "    'axis':1,\n",
    "    'epsilon':1e-5,\n",
    "    'center':True\n",
    "}\n",
    "\n",
    "def pconv3X3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "def kconv3x3(out_planes, stride=1, name=None):\n",
    "    return Conv2D(out_planes, kernel_size=3, strides=stride, padding='same', use_bias=False, name=name)\n",
    "\n",
    "class pBasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes, batchNorm_type=0, stride=1, downsample=None):\n",
    "        super(pBasicBlock, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.outplanes = outplanes\n",
    "        self.conv1 = pconv3X3(inplanes, outplanes, 1)\n",
    "        self.conv2 = pconv3X3(outplanes, outplanes, 1)\n",
    "        if batchNorm_type == 0:\n",
    "            self.bn1 = nn.BatchNorm2d(outplanes)\n",
    "            self.bn2 = nn.BatchNorm2d(outplanes)\n",
    "        else:\n",
    "            self.bn1 = nn.InstanceNorm2d(outplanes)\n",
    "            self.bn2 = nn.InstanceNorm2d(outplanes)\n",
    "        self.shortcuts = nn.Conv2d(inplanes, outplanes, kernel_size=1, stride=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.inplanes != self.outplanes:\n",
    "            out += self.shortcuts(x)\n",
    "        else:\n",
    "            out += x\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "def kBasicBlock(inplanes, outplanes, batchNorm_type=0, name=None):\n",
    "    x = Input(shape=(inplanes, None, None))\n",
    "    out = kconv3x3(outplanes, 1, name='conv1')(x)\n",
    "    if batchNorm_type == 0:\n",
    "        out = BatchNormalization(**bnopt, name='bn1')(out)\n",
    "    elif batchNorm_type == 1:\n",
    "        out = InstanceNormalization(**bnopt, name='in1')(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = kconv3x3(outplanes, 1, name='conv2')(out)\n",
    "    if batchNorm_type == 0:\n",
    "        out = BatchNormalization(**bnopt, name='bn2')(out)\n",
    "    elif batchNorm_type == 1:\n",
    "        out = InstanceNormalization(**bnopt, name='in2')(out)\n",
    "    shortcuts = Conv2D(outplanes, kernel_size=1, strides=1, use_bias=False, name='shortcuts')(x)\n",
    "    if (inplanes != outplanes):\n",
    "        out = Add()([out, shortcuts])\n",
    "    else:\n",
    "        out = Add()([out, x])\n",
    "    out = Activation('relu')(out)\n",
    "    return Model(inputs=x, outputs=out, name=name)\n",
    "\n",
    "# x = np.random.rand(1,64,6,6)\n",
    "# kmodel_ = kBasicBlock(64, 155, batchNorm_type=0)\n",
    "# pmodel_ = pmodel.HG0.low1 #pBasicBlock(2, 4)\n",
    "\n",
    "# kmodel_ = pbblock_to_kbblock(pmodel_, kmodel_)\n",
    "\n",
    "# pout = npa(pmodel_(tt(x)))\n",
    "# kout = kmodel_.predict(x)\n",
    "# diff = np.abs(pout - kout)\n",
    "# print(np.abs(pout).mean(), np.abs(kout).mean(), diff.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pconv2d_to_kconv2d(pconv, kconv): #assuming keras channels_first\n",
    "    pweights = npa(pconv.weight)\n",
    "    kweights = np.transpose(pweights, (2,3,1,0))\n",
    "    if (pconv.bias is None):\n",
    "        kconv.set_weights([kweights])\n",
    "    else:\n",
    "        pbias = npa(pconv.bias)\n",
    "        kconv.set_weights([kweights, pbias])\n",
    "    return kconv\n",
    "\n",
    "def pbatchnorm_to_kbatchnorm(player, klayer):\n",
    "    pweights = npa(player.weight)\n",
    "    kweights = klayer.get_weights()\n",
    "    kweights[0] = pweights\n",
    "    if (player.bias is not None):\n",
    "        kweights[1] = npa(player.bias)\n",
    "    klayer.set_weights(kweights)\n",
    "    return klayer\n",
    "\n",
    "def pbblock_to_kbblock(pmodel, kmodel): #fix bn1 and bn2 \n",
    "    klayer_names = [layer.name for layer in kmodel.layers]\n",
    "    pconv2d_to_kconv2d(pmodel.conv1, kmodel.get_layer('conv1'))\n",
    "    pconv2d_to_kconv2d(pmodel.conv2, kmodel.get_layer('conv2'))\n",
    "    #if (pmodel.inplanes != pmodel.outplanes):\n",
    "    if ('shortcuts' in klayer_names):\n",
    "        pconv2d_to_kconv2d(pmodel.shortcuts, kmodel.get_layer('shortcuts'))\n",
    "    if ('bn1' in klayer_names) and ('bn2' in klayer_names):\n",
    "        pbatchnorm_to_kbatchnorm(pmodel.bn1, kmodel.get_layer('bn1'))\n",
    "        pbatchnorm_to_kbatchnorm(pmodel.bn2, kmodel.get_layer('bn2'))\n",
    "    return kmodel\n",
    "\n",
    "def pprelu_to_kprelu(pprelu, kprelu):\n",
    "    alpha = npa(pprelu.weight)[0]\n",
    "    kprelu.set_weights([np.ones_like(kprelu.get_weights()[0])*alpha])\n",
    "    return kprelu\n",
    "\n",
    "def plightnet_to_klightnet(pmodel, kmodel):\n",
    "    pconv2d_to_kconv2d(pmodel.predict_FC1, kmodel.get_layer('predict_FC1'))\n",
    "    pconv2d_to_kconv2d(pmodel.predict_FC2, kmodel.get_layer('predict_FC2'))\n",
    "    pprelu_to_kprelu(pmodel.predict_relu1, kmodel.get_layer('predict_relu1'))\n",
    "\n",
    "    pconv2d_to_kconv2d(pmodel.post_FC1, kmodel.get_layer('post_FC1'))\n",
    "    pconv2d_to_kconv2d(pmodel.post_FC2, kmodel.get_layer('post_FC2'))\n",
    "    pprelu_to_kprelu(pmodel.post_relu1, kmodel.get_layer('post_relu1'))\n",
    "    return kmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Weight conversion of conv2D\n",
    "\n",
    "# x = np.random.rand(1,2,6,6)\n",
    "# W = np.random.rand(2,2,3,3) #np.ones((2,2,3,3))\n",
    "\n",
    "# #pconv.weight = torch.nn.Parameter(tt(W))\n",
    "# #pconv2d_to_kconv2d(pconv, kconv.layers[1])\n",
    "# #kconv2d_to_pconv2d(kconv.layers[1], pconv)\n",
    "\n",
    "# kconv = kconv3x3(2, 2)\n",
    "# #print(kconv.weights[0].numpy().shape)\n",
    "# #print(kconv.weights[0].numpy())\n",
    "# #print(kconv.predict(x))\n",
    "\n",
    "# pconv = pconv3X3(2, 2)\n",
    "# #print(npa(pconv.weight).shape)\n",
    "# #print(npa(pconv.weight))\n",
    "# #print(npa(pconv(tt(x))))\n",
    "\n",
    "# print(pconv.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # Matching of BatchNorm\n",
    "\n",
    "# def kbatchnorm(dim):\n",
    "#     x = Input(shape=(dim,None,None))\n",
    "#     out = BatchNormalization(**bnopt_bias)(x)\n",
    "#     #out = InstanceNormalization(**bnopt_bias)(x)\n",
    "#     return Model(inputs=x, outputs=out)\n",
    "\n",
    "# # def pbatchnorm(dim):\n",
    "# #     return nn.BatchNorm2d(dim)\n",
    "# #     #return nn.InstanceNorm2d(dim)\n",
    "\n",
    "# x = np.random.rand(1,155,100,100)\n",
    "\n",
    "# kbn = kbatchnorm(155)\n",
    "# pbn = pmodel.HG0.low1.bn2\n",
    "# # pbn = pbatchnorm(2)\n",
    "# # pbn.bias = nn.Parameter(tt([2.0, 2.0]))\n",
    "# pbatchnorm_to_kbatchnorm(pbn, kbn.layers[1])\n",
    "\n",
    "# pout = npa(pbn(tt(x))).flatten()\n",
    "# kout = kbn.predict(x).flatten()\n",
    "# diff = np.abs(pout - kout)\n",
    "# print(np.abs(pout).mean(), np.abs(kout).mean(), diff.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Matching BasicBlock\n",
    "\n",
    "# x = np.random.rand(1,2,6,6)\n",
    "\n",
    "# kmodel = kBasicBlock(2, 4)\n",
    "# pmodel = pBasicBlock(2, 4)\n",
    "\n",
    "# pbblock_to_kbblock(pmodel, kmodel)\n",
    "\n",
    "# pout = npa(pmodel(tt(x)))\n",
    "# kout = kmodel.predict(x)\n",
    "# diff = np.abs(pout - kout)\n",
    "# print(np.abs(pout).mean(), np.abs(kout).mean(), diff.mean())\n",
    "\n",
    "# # kmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lightingNets and compare them\n",
    "\n",
    "class plightingNet(nn.Module):\n",
    "    def __init__(self, ncInput, ncOutput, ncMiddle):\n",
    "        super(plightingNet, self).__init__()\n",
    "        self.ncInput = ncInput\n",
    "        self.ncOutput = ncOutput\n",
    "        self.ncMiddle = ncMiddle\n",
    "        self.predict_FC1 = nn.Conv2d(self.ncInput,  self.ncMiddle, kernel_size=1, stride=1, bias=False)\n",
    "        self.predict_relu1 = nn.PReLU()\n",
    "        self.predict_FC2 = nn.Conv2d(self.ncMiddle, self.ncOutput, kernel_size=1, stride=1, bias=False)\n",
    "\n",
    "        self.post_FC1 = nn.Conv2d(self.ncOutput,  self.ncMiddle, kernel_size=1, stride=1, bias=False)\n",
    "        self.post_relu1 = nn.PReLU()\n",
    "        self.post_FC2 = nn.Conv2d(self.ncMiddle, self.ncInput, kernel_size=1, stride=1, bias=False)\n",
    "        self.post_relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, innerFeat, target_light):\n",
    "        x = innerFeat[:,0:self.ncInput,:,:] # lighting feature\n",
    "        _, _, row, col = x.shape\n",
    "        # predict lighting\n",
    "        feat = x.mean(dim=(2,3), keepdim=True)\n",
    "        light = self.predict_relu1(self.predict_FC1(feat))\n",
    "        light = self.predict_FC2(light)\n",
    "        # get back the feature space\n",
    "        upFeat = self.post_relu1(self.post_FC1(target_light))\n",
    "        upFeat = self.post_relu2(self.post_FC2(upFeat))\n",
    "        upFeat = upFeat.repeat((1,1,row, col))\n",
    "        innerFeat[:,0:self.ncInput,:,:] = upFeat\n",
    "        return innerFeat, light\n",
    "\n",
    "def klightingNet(ncInput, ncOutput, ncMiddle, name=None): #27, 9, 128 #len(zs), #SH coeff, ...\n",
    "    innerFeat = Input(shape=(None, None, None)) #155,32,32\n",
    "    x = Lambda(lambda x_: K.slice(x_, (0,0,0,0), (-1,ncInput,-1,-1)))(innerFeat) #27,32,32\n",
    "    #row, col = K.shape(x)[2], K.shape(x)[3] #32,32\n",
    "\n",
    "    feat = Lambda(lambda x_: K.mean(x_, axis=(2,3), keepdims=True))(x) #27,32,32\n",
    "    pred_light = Conv2D(ncMiddle, kernel_size=1, strides=1, use_bias=False, name='predict_FC1')(feat) #128,32,32\n",
    "    pred_light = PReLU(shared_axes=[2,3], name='predict_relu1')(pred_light) #shared_axes solves bug in tf 1.13. not sure of side-effect.\n",
    "    pred_light = Conv2D(ncOutput, kernel_size=1, strides=1, use_bias=False, name='predict_FC2')(pred_light) #9,32,32\n",
    "\n",
    "    target_light = Input(shape=(ncOutput, None, None)) #9,1,1\n",
    "    upFeat = Conv2D(ncMiddle, kernel_size=1, strides=1, use_bias=False, name='post_FC1')(target_light) #128,1,1\n",
    "    upFeat = PReLU(shared_axes=[2,3], name='post_relu1')(upFeat) #shared_axes solves bug in tf 1.13. not sure of side-effect.\n",
    "    upFeat = Conv2D(ncInput, kernel_size=1, strides=1, use_bias=False, name='post_FC2')(upFeat) #27,1,1\n",
    "    upFeat = ReLU()(upFeat)\n",
    "    upFeat = Lambda(lambda x_: K.tile(x_, (1, 1, 32, 32)))(upFeat) #27,32,32 #had to hard-code this\n",
    "    #upFeat = Lambda(lambda x_: K.tile(x_, (1, 1, row, col)))(upFeat) #27,32,32?\n",
    "\n",
    "    x2 = Lambda(lambda x_: K.slice(x_, (0,ncInput,0,0), (-1,-1,-1,-1)))(innerFeat) #27,32,32\n",
    "    xout = Concatenate(axis=1)([upFeat, x2]) #155,32,32\n",
    "    return Model(inputs=[innerFeat, target_light], outputs=[xout, pred_light], name=name) #(155, 32, 32), (9, 1, 1)\n",
    "\n",
    "# ninp, nout, nmid = 27, 9, 128\n",
    "# row, col = 32, 32\n",
    "# x = np.random.rand(1, 155, row, col)\n",
    "# tlight = np.ones((1, nout, 1, 1))\n",
    "\n",
    "# plnet = plightingNet(ninp, nout, nmid)\n",
    "# pout = plnet(tt(x), tt(tlight))\n",
    "\n",
    "# klnet = klightingNet(ninp, nout, nmid)\n",
    "# klnet = plightnet_to_klightnet(plnet, klnet)\n",
    "# kout = klnet.predict([x, tlight])\n",
    "\n",
    "# for i in range(2):\n",
    "#     x1 = npa(pout[i])\n",
    "#     x2 = kout[i]\n",
    "#     diff = np.abs(x1-x2)\n",
    "#     print(x1.mean(), x2.mean(), diff.mean())\n",
    "\n",
    "# print(pout[0].shape, pout[1].shape)\n",
    "# print(kout[0].shape, kout[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HourglassBlocks and compare them\n",
    "\n",
    "class pHourglassBlock(nn.Module):\n",
    "    def __init__(self, inplane, mid_plane, middleNet):\n",
    "        super(pHourglassBlock, self).__init__()\n",
    "        # upper branch\n",
    "        self.upper = pBasicBlock(inplane, inplane, batchNorm_type=1)\n",
    "        # lower branch\n",
    "        self.downSample = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.low1 = pBasicBlock(inplane, mid_plane)\n",
    "        self.middle = middleNet\n",
    "        self.low2 = pBasicBlock(mid_plane, inplane, batchNorm_type=1)\n",
    "        self.upSample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x, light):\n",
    "        out_upper = self.upper(x)\n",
    "        out_lower = self.downSample(x)\n",
    "        out_lower = self.low1(out_lower)\n",
    "        out_lower, out_middle = self.middle(out_lower, light)\n",
    "        out_lower = self.low2(out_lower)\n",
    "        out_lower = self.upSample(out_lower)\n",
    "        out = out_lower + out_upper\n",
    "        return out, out_middle\n",
    "\n",
    "# We assume skip_count=0, and don't implement count\n",
    "def kHourglassBlock(inplane, mid_plane, middleNet, name=None): #64, 155, klnet(27,9,128)\n",
    "    x = Input(shape=(inplane, None, None)) #64,64,64\n",
    "    target_light = Input(shape=(9, None, None)) #9,1,1 #hardcoded -> nout\n",
    "    out_upper = kBasicBlock(inplane, inplane, batchNorm_type=1, name='upper')(x) #64,64,64\n",
    "    out_lower = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='downsample')(x) #64,32,32\n",
    "    out_lower = kBasicBlock(inplane, mid_plane, name='low1')(out_lower) #155,32,32 (OK)\n",
    "    out_lower, pred_light = middleNet([out_lower, target_light]) #(155,32,32), (9,1,1) -> (155,32,32), (9,1,1)\n",
    "    out_lower = kBasicBlock(mid_plane, inplane, batchNorm_type=1, name='low2')(out_lower) #64,32,32\n",
    "    out_lower = UpSampling2D(size=(2, 2), name='upsample')(out_lower) #64,64,64\n",
    "    out = Add()([out_lower, out_upper]) #64,64,64\n",
    "    return Model(inputs=[x, target_light], outputs=[out, pred_light], name=name) #(64,64,64), (9,1,1)\n",
    "\n",
    "def phgblock_to_khgblock(pmodel, kmodel):\n",
    "    klayer_names = [layer.name for layer in kmodel.layers]\n",
    "    pbblock_to_kbblock(pmodel.upper, kmodel.get_layer('upper'))\n",
    "    pbblock_to_kbblock(pmodel.low1, kmodel.get_layer('low1'))\n",
    "    pbblock_to_kbblock(pmodel.low2, kmodel.get_layer('low2'))\n",
    "    if ('klnet' in klayer_names):\n",
    "        plightnet_to_klightnet(pmodel.middle, kmodel.get_layer('klnet'))\n",
    "    else:\n",
    "        hg_layers = [s for s in klayer_names if 'HG' in s]\n",
    "        phgblock_to_khgblock(pmodel.middle, kmodel.get_layer(hg_layers[0]))\n",
    "    return kmodel\n",
    "\n",
    "# ninp, nout, nmid = 27, 9, 128\n",
    "# row, col = 64, 64\n",
    "# inplane, mid_plane = 64, 155\n",
    "# klnet_input = [np.random.rand(1, mid_plane, row//2, col//2), np.ones((1, nout, 1, 1))] #(155,32,32), (9,1,1)\n",
    "# hgnet_input = [np.random.rand(1, inplane, row, col), np.ones((1, nout, 1, 1))] #(64,64,64), (9,1,1)\n",
    "\n",
    "# plnet_ = pmodel.light #plightingNet(ninp, nout, nmid)\n",
    "# pmodel_ = pmodel.HG0 #pHourglassBlock(inplane, mid_plane, plnet)\n",
    "# pout = pmodel_(tt(hgnet_input[0]), tt(hgnet_input[1]))\n",
    "\n",
    "# klnet_ = klightingNet(ninp, nout, nmid, name='klnet')\n",
    "# klnet_ = plightnet_to_klightnet(plnet_, klnet_)\n",
    "# kmodel_ = kHourglassBlock(inplane, mid_plane, klnet_)\n",
    "# kmodel_ = phgblock_to_khgblock(pmodel_, kmodel_)\n",
    "# kout = kmodel_.predict(hgnet_input)\n",
    "\n",
    "# for i in range(2):\n",
    "#     x1 = npa(pout[i])\n",
    "#     x2 = kout[i]\n",
    "#     diff = np.abs(x1-x2)\n",
    "#     print(x1.mean(), x2.mean(), diff.mean())\n",
    "\n",
    "# print(pout[0].shape, pout[1].shape)\n",
    "# print(kout[0].shape, kout[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HourglassNets and compare them\n",
    "\n",
    "class pHourglassNet(nn.Module):\n",
    "    def __init__(self, baseFilter = 16, gray=True):\n",
    "        super(pHourglassNet, self).__init__()\n",
    "        self.ncLight = 27   # number of channels for input to lighting network\n",
    "        self.baseFilter = baseFilter\n",
    "\n",
    "        # number of channles for output of lighting network\n",
    "        if gray:\n",
    "            self.ncOutLight = 9  # gray: channel is 1\n",
    "        else:\n",
    "            self.ncOutLight = 27  # color: channel is 3\n",
    "\n",
    "        self.ncPre = self.baseFilter  # number of channels for pre-convolution\n",
    "        # number of channels \n",
    "        self.ncHG3 = self.baseFilter\n",
    "        self.ncHG2 = 2*self.baseFilter\n",
    "        self.ncHG1 = 4*self.baseFilter\n",
    "        self.ncHG0 = 8*self.baseFilter + self.ncLight\n",
    "\n",
    "        self.pre_conv = nn.Conv2d(1, self.ncPre, kernel_size=5, stride=1, padding=2)\n",
    "        self.pre_bn = nn.BatchNorm2d(self.ncPre)\n",
    "\n",
    "        self.light = plightingNet(self.ncLight, self.ncOutLight, 128)\n",
    "        self.HG0 = pHourglassBlock(self.ncHG1, self.ncHG0, self.light)\n",
    "        self.HG1 = pHourglassBlock(self.ncHG2, self.ncHG1, self.HG0)\n",
    "        self.HG2 = pHourglassBlock(self.ncHG3, self.ncHG2, self.HG1)\n",
    "        self.HG3 = pHourglassBlock(self.ncPre, self.ncHG3, self.HG2)\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(self.ncPre, self.ncPre, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_1 = nn.BatchNorm2d(self.ncPre) \n",
    "        self.conv_2 = nn.Conv2d(self.ncPre, self.ncPre, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn_2 = nn.BatchNorm2d(self.ncPre) \n",
    "        self.conv_3 = nn.Conv2d(self.ncPre, self.ncPre, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn_3 = nn.BatchNorm2d(self.ncPre)\n",
    "\n",
    "        self.output = nn.Conv2d(self.ncPre, 1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x, target_light): #, skip_count):\n",
    "        feat = self.pre_conv(x)\n",
    "        feat = F.relu(self.pre_bn(feat))\n",
    "        feat, out_light = self.HG3(feat, target_light) #, 0, skip_count)\n",
    "        feat = F.relu(self.bn_1(self.conv_1(feat)))\n",
    "        feat = F.relu(self.bn_2(self.conv_2(feat)))\n",
    "        feat = F.relu(self.bn_3(self.conv_3(feat)))\n",
    "        out_img = self.output(feat)\n",
    "        out_img = torch.sigmoid(out_img)\n",
    "        return out_img, out_light\n",
    "\n",
    "def kHourglassNet(baseFilter=16, name=None):\n",
    "    x = Input(shape=(1, None, None)) #1,512,512\n",
    "    target_light = Input(shape=(9, None, None)) #9,1,1 #hardcoded -> nout\n",
    "    feat = keras.layers.ZeroPadding2D(padding=(2, 2))(x)\n",
    "    feat = Conv2D(baseFilter, kernel_size=5, strides=1, padding='valid', name='pre_conv')(feat)\n",
    "    feat = BatchNormalization(**bnopt_bias, name='pre_bn')(feat)\n",
    "    feat = Activation('relu')(feat)\n",
    "\n",
    "    ncPre = baseFilter\n",
    "    ncLight = 27\n",
    "    ncOutLight = 9\n",
    "    ncHG3 = baseFilter\n",
    "    ncHG2 = 2*baseFilter\n",
    "    ncHG1 = 4*baseFilter\n",
    "    ncHG0 = 8*baseFilter + ncLight\n",
    "\n",
    "    klnet = klightingNet(ncLight, ncOutLight, 128, name='klnet')\n",
    "    HG0 = kHourglassBlock(ncHG1, ncHG0, klnet, name='HG0')\n",
    "    HG1 = kHourglassBlock(ncHG2, ncHG1, HG0, name='HG1')\n",
    "    HG2 = kHourglassBlock(ncHG3, ncHG2, HG1, name='HG2')\n",
    "    HG3 = kHourglassBlock(ncPre, ncHG3, HG2, name='HG3')\n",
    "    feat, out_light = HG3([feat, target_light])\n",
    "\n",
    "    feat = Conv2D(ncPre, kernel_size=3, strides=1, padding='same', name='conv_1')(feat)\n",
    "    feat = BatchNormalization(**bnopt_bias, name='bn_1')(feat)\n",
    "    feat = Activation('relu')(feat)\n",
    "\n",
    "    feat = Conv2D(ncPre, kernel_size=1, strides=1, padding='valid', name='conv_2')(feat)\n",
    "    feat = BatchNormalization(**bnopt_bias, name='bn_2')(feat)\n",
    "    feat = Activation('relu')(feat)\n",
    "\n",
    "    feat = Conv2D(ncPre, kernel_size=1, strides=1, padding='valid', name='conv_3')(feat)\n",
    "    feat = BatchNormalization(**bnopt_bias, name='bn_3')(feat)\n",
    "    feat = Activation('relu')(feat)\n",
    "\n",
    "    out_img = Conv2D(1, kernel_size=1, strides=1, padding='valid', name='output')(feat)\n",
    "    out_img = Activation('sigmoid')(out_img)\n",
    "    return Model(inputs=[x, target_light], outputs=[out_img, out_light], name=name)\n",
    "\n",
    "def phgnet_to_khgnet(pmodel, kmodel):\n",
    "    pconv2d_to_kconv2d(pmodel.pre_conv, kmodel.get_layer('pre_conv'))\n",
    "    pbatchnorm_to_kbatchnorm(pmodel.pre_bn, kmodel.get_layer('pre_bn'))\n",
    "    phgblock_to_khgblock(pmodel.HG3, kmodel.get_layer('HG3'))\n",
    "    pconv2d_to_kconv2d(pmodel.conv_1, kmodel.get_layer('conv_1'))\n",
    "    pbatchnorm_to_kbatchnorm(pmodel.bn_1, kmodel.get_layer('bn_1'))\n",
    "    pconv2d_to_kconv2d(pmodel.conv_2, kmodel.get_layer('conv_2'))\n",
    "    pbatchnorm_to_kbatchnorm(pmodel.bn_2, kmodel.get_layer('bn_2'))\n",
    "    pconv2d_to_kconv2d(pmodel.conv_3, kmodel.get_layer('conv_3'))\n",
    "    pbatchnorm_to_kbatchnorm(pmodel.bn_3, kmodel.get_layer('bn_3'))\n",
    "    pconv2d_to_kconv2d(pmodel.output, kmodel.get_layer('output'))\n",
    "    return kmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# inputL = np.random.rand(1, 1, 512, 512)\n",
    "# sh = np.random.rand(1, 9, 1, 1)\n",
    "\n",
    "# pmodel = pHourglassNet()\n",
    "# pmodel.load_state_dict(torch.load(os.path.join(modelFolder, 'trained_model_03.t7')))\n",
    "# pout = pmodel(tt(inputL), tt(sh))\n",
    "\n",
    "# kmodel = kHourglassNet(name='hgnet')\n",
    "# kmodel = phgnet_to_khgnet(pmodel, kmodel)\n",
    "# kout = kmodel.predict([inputL, sh])\n",
    "\n",
    "# for i in range(2):\n",
    "#     x1 = npa(pout[i])\n",
    "#     x2 = kout[i]\n",
    "#     diff = np.abs(x1-x2)\n",
    "#     print(x1.mean(), x2.mean(), diff.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 288x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2, os\n",
    "\n",
    "modelFolder = 'trained_model/'\n",
    "lightFolder = 'data/example_light/'\n",
    "saveFolder = 'result'\n",
    "\n",
    "pmodel = pHourglassNet()\n",
    "pmodel.load_state_dict(torch.load(os.path.join(modelFolder, 'trained_model_03.t7')))\n",
    "pmodel.train(True) #best results with True\n",
    "# pmodel.cuda()\n",
    "\n",
    "img = cv2.imread('data/online_guy.jfif')\n",
    "row, col, _ = img.shape\n",
    "img = cv2.resize(img, (512, 512))\n",
    "Lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "inputL = Lab[:, :, 0]\n",
    "inputL = inputL.astype(np.float32)/255.0\n",
    "inputL = inputL.transpose((0,1))\n",
    "inputL = inputL[None, None, ...]\n",
    "### inputL = torch.from_numpy(inputL)\n",
    "\n",
    "plt.figure(figsize=(4,10))\n",
    "\n",
    "for i in range(7):\n",
    "    sh = np.loadtxt(os.path.join(lightFolder, 'rotate_light_{:02d}.txt'.format(i)))[0:9]\n",
    "    sh = 0.7 * sh\n",
    "    sh = np.reshape(sh, (1, 9, 1, 1)).astype(np.float32)\n",
    "\n",
    "    pimg, psh = pmodel(tt(inputL), tt(sh))\n",
    "    pimg = pimg[0].cpu().data.numpy()\n",
    "    pimg = pimg.transpose((1,2,0))\n",
    "    pimg = np.squeeze(pimg)\n",
    "    pimg = (pimg*255.0).astype(np.uint8)\n",
    "    Lab[:,:,0] = pimg\n",
    "    resultLab = cv2.cvtColor(Lab, cv2.COLOR_LAB2BGR)\n",
    "    resultLab = cv2.resize(resultLab, (col, row))\n",
    "\n",
    "    #resultLab = cv2.cvtColor(resultLab, cv2.COLOR_BGR2RGB)\n",
    "    #plt.imshow(resultLab)\n",
    "    #cv2.imwrite('ponline_guy_traintrue_new.jpg', resultLab)\n",
    "    cv2.imwrite(os.path.join(saveFolder, 'pytorch_online_guy_{:02d}.jpg'.format(i)), resultLab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmodel.layers[6].layers[2].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.78985133333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def set_trainable(model, val=True):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = val\n",
    "        if 'layers' in dir(layer):\n",
    "            set_trainable(layer, val)\n",
    "\n",
    "# saveFolder = 'keras/results/no_bn'\n",
    "# K.set_learning_phase(1)\n",
    "# kmodel = kHourglassNet(name='hgnet')\n",
    "# kmodel = phgnet_to_khgnet(pmodel, kmodel)\n",
    "#kmodel.trainable = True\n",
    "set_trainable(kmodel, False)\n",
    "\n",
    "for i in range(1):\n",
    "    sh = np.loadtxt(os.path.join(lightFolder, 'rotate_light_{:02d}.txt'.format(i)))[0:9]\n",
    "    sh = 0.7 * sh\n",
    "    sh = np.reshape(sh, (1, 9, 1, 1)).astype(np.float32)\n",
    "\n",
    "    kimg, ksh = kmodel.predict([inputL, sh])\n",
    "    kimg = kimg[0].transpose((1,2,0))\n",
    "    kimg = np.squeeze(kimg)\n",
    "    kimg = (kimg*255.0).astype(np.uint8)\n",
    "    Lab[:,:,0] = kimg\n",
    "    resultLab = cv2.cvtColor(Lab, cv2.COLOR_LAB2BGR)\n",
    "    resultLab = cv2.resize(resultLab, (col, row))\n",
    "    print(resultLab.mean())\n",
    "    #resultLab = cv2.cvtColor(resultLab, cv2.COLOR_BGR2RGB)\n",
    "    #plt.imshow(resultLab)\n",
    "    #cv2.imwrite('konline_guy_traintrue_new.jpg', resultLab)\n",
    "    #cv2.imwrite(os.path.join(saveFolder, 'keras_online_guy_{:02d}.jpg'.format(i)), resultLab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-70fc365addcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'InstanceNormalization'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mInstanceNormalization\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trained_model_03.weights.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[1;32m-> 1166\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   1043\u001b[0m                                                        \u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m                                                        \u001b[0moriginal_backend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m                                                        reshape=reshape)\n\u001b[0m\u001b[0;32m   1046\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             raise ValueError('Layer #' + str(k) +\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[1;34m(layer, weights, original_keras_version, original_backend, reshape)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_time_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sequential'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moriginal_keras_version\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mconvert_nested_model\u001b[1;34m(weights)\u001b[0m\n\u001b[0;32m    656\u001b[0m                     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m                     \u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                     original_backend=original_backend))\n\u001b[0m\u001b[0;32m    659\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[1;34m(layer, weights, original_keras_version, original_backend, reshape)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_time_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sequential'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moriginal_keras_version\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mconvert_nested_model\u001b[1;34m(weights)\u001b[0m\n\u001b[0;32m    656\u001b[0m                     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m                     \u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                     original_backend=original_backend))\n\u001b[0m\u001b[0;32m    659\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[1;34m(layer, weights, original_keras_version, original_backend, reshape)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_time_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sequential'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moriginal_keras_version\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mconvert_nested_model\u001b[1;34m(weights)\u001b[0m\n\u001b[0;32m    656\u001b[0m                     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m                     \u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                     original_backend=original_backend))\n\u001b[0m\u001b[0;32m    659\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[1;34m(layer, weights, original_keras_version, original_backend, reshape)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_time_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sequential'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moriginal_keras_version\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mconvert_nested_model\u001b[1;34m(weights)\u001b[0m\n\u001b[0;32m    668\u001b[0m                     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                     \u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m                     original_backend=original_backend))\n\u001b[0m\u001b[0;32m    671\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[1;34m(layer, weights, original_keras_version, original_backend, reshape)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_time_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sequential'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moriginal_keras_version\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mconvert_nested_model\u001b[1;34m(weights)\u001b[0m\n\u001b[0;32m    656\u001b[0m                     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m                     \u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                     original_backend=original_backend))\n\u001b[0m\u001b[0;32m    659\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[1;34m(layer, weights, original_keras_version, original_backend, reshape)\u001b[0m\n\u001b[0;32m    798\u001b[0m                                  str(weights[0].size) + '. ')\n\u001b[0;32m    799\u001b[0m             \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_weights_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlayer_weights_shape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m             \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ConvLSTM2D'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#kmodel.save('trained_model_03.h5')\n",
    "# kmodel_json = kmodel.to_json()\n",
    "# with open('trained_model_03.json', 'w') as json_file:\n",
    "#     json_file.write(kmodel_json)\n",
    "# kmodel.save_weights(\"trained_model_03.weights.h5\")\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# model = load_model('trained_model_03.h5')\n",
    "\n",
    "json_file = open('trained_model_03.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json, custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "model.load_weights(\"trained_model_03.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odict = torch.load(os.path.join(modelFolder, 'trained_model_03.t7'))\n",
    "# keys = odict.keys()\n",
    "# # set([key.split('.')[-1] for key in keys])\n",
    "# for key in keys:\n",
    "#     if 'HG0.low1' in key: #key.split('.')[-1]:\n",
    "#         print(key, odict[key].shape) #odict[key])\n",
    "\n",
    "# print(K.eval(kbn.layers[1].moving_mean))\n",
    "# print(pbn.running_mean)\n",
    "\n",
    "# print(K.eval(kbn.layers[1].moving_variance))\n",
    "# print(pbn.running_var)\n",
    "\n",
    "#dir(kbn.layers[1])\n",
    "#  'moving_mean',\n",
    "#  'moving_mean_initializer',\n",
    "#  'moving_variance',\n",
    "#  'moving_variance_initializer',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('model')\n",
    "# #import defineHourglass_512_gray_skip as pyt\n",
    "# my_network = pyt.HourglassNet()\n",
    "# my_network.load_state_dict(torch.load('trained_model/trained_model_03.t7'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class KBasicBlock(keras.Model):\n",
    "#     def __init__(self, inplanes, outplanes, batchNorm_type=0):\n",
    "#         super(KBasicBlock, self).__init__()\n",
    "#         self.inplanes = inplanes\n",
    "#         self.outplanes = outplanes\n",
    "#         self.conv1 = kconv3x3(inplanes, outplanes, 1)\n",
    "#         self.conv2 = kconv3x3(outplanes, outplanes, 1)\n",
    "#         self.shortcuts = Conv2D(outplanes, kernel_size=3, strides=1, use_bias=False)\n",
    "#         if batchNorm_type == 0:\n",
    "#             self.bn1 = BatchNormalization(**bnopt)\n",
    "#             self.bn2 = BatchNormalization(**bnopt)\n",
    "#         else: #FIX\n",
    "#             self.bn1 = BatchNormalization(**bnopt)\n",
    "#             self.bn2 = BatchNormalization(**bnopt)\n",
    "\n",
    "#     def call(self, x):\n",
    "#         out = self.conv1(x)\n",
    "#         out = self.bn1(out)\n",
    "#         out = Activation('relu')(out)\n",
    "#         out = self.conv2(out)\n",
    "#         out = self.bn2(out)\n",
    "#         aux = self.shortcuts(x)\n",
    "#         if self.inplanes != self.outplanes:\n",
    "#             out = Add()([out, aux]) #self.shortcuts(x)\n",
    "#         else:\n",
    "#             out = Add()([out, x])\n",
    "#         out = Activation('relu')(out)\n",
    "#         return out\n",
    "\n",
    "# class KHourglassBlock(keras.Model):\n",
    "#     def __init__(self, inplane, mid_plane, middleNet):\n",
    "#         super(KHourglassBlock, self).__init__()\n",
    "#         # upper branch\n",
    "#         self.upper = kBasicBlock(inplane, inplane, batchNorm_type=1) #FIX\n",
    "#         # lower branch\n",
    "#         self.downSample = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "#         self.low1 = kBasicBlock(inplane, mid_plane)\n",
    "#         self.middle = middleNet\n",
    "#         self.low2 = kBasicBlock(mid_plane, inplane, batchNorm_type=1) #FIX\n",
    "#         self.upsample = UpSampling2D(size=(2, 2))\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x = inputs[0]\n",
    "#         target_light = inputs[1]\n",
    "#         out_upper = self.upper(x)\n",
    "#         out_lower = self.downSample(x)\n",
    "#         out_lower = self.low1(out_lower)\n",
    "#         out_lower, pred_light = self.middle([out_lower, target_light])\n",
    "#         out_lower = self.low2(out_lower)\n",
    "#         out_lower = self.upsample(out_lower)\n",
    "#         out = Add()([out_lower, out_upper])\n",
    "#         return out, pred_light\n",
    "\n",
    "#conc = Lambda(lambda x_: Concatenate(axis=1)([x_[0], x_[1]]))([out_lower, light])\n",
    "#out_lower, out_middle = middleNet(Concatenate(mode='ave')([out_lower, light]))\n",
    "#out_lower, out_middle = middleNet(conc)\n",
    "#out_lower, out_middle = middleNet.call([out_lower, light])\n",
    "#out_lower, out_middle = Lambda(middleNet)((out_lower, light)) \n",
    "\n",
    "# class KlightingNet(keras.Model):\n",
    "#     def __init__(self, ncInput, ncOutput, ncMiddle):\n",
    "#         super(KlightingNet, self).__init__()\n",
    "\n",
    "#         self.ncInput = ncInput\n",
    "#         self.ncOutput = ncOutput\n",
    "#         self.ncMiddle = ncMiddle\n",
    "\n",
    "#         self.slicer = Lambda(lambda x_: K.slice(x_, (0,0,0,0), (-1,self.ncInput,-1,-1)))\n",
    "#         self.predict_mean = Lambda(lambda x_: K.mean(x_, axis=(2,3), keepdims=True))\n",
    "#         self.predict_FC1 = Conv2D(ncMiddle, kernel_size=1, strides=1, use_bias=False, name='predict_FC1')\n",
    "#         self.predict_relu1 = PReLU(name='predict_relu1')\n",
    "#         self.predict_FC2 = Conv2D(ncOutput, kernel_size=1, strides=1, use_bias=False, name='predict_FC2')\n",
    "\n",
    "#         self.post_FC1 = Conv2D(ncMiddle, kernel_size=1, strides=1, use_bias=False, name='post_FC1')\n",
    "#         self.post_relu1 = PReLU(shared_axes=[2,3], name='post_relu1')\n",
    "#         self.post_FC2 = Conv2D(ncInput, kernel_size=1, strides=1, use_bias=False, name='post_FC2')\n",
    "#         self.post_relu2 = ReLU()\n",
    "#         self.post_tiler = Lambda(lambda x_: K.tile(x_, (1, 1, row, col)))\n",
    "\n",
    "#         self.slicer_x1 = Lambda(lambda x_: x_[:, 0:self.ncInput, :, :])\n",
    "#         self.slicer_x2 = Lambda(lambda x_: x_[:, self.ncInput:, :, :])\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         innerFeat = inputs[0]\n",
    "#         x = self.slicer(innerFeat)\n",
    "#         row, col = K.shape(x)[2], K.shape(x)[3]\n",
    "#         feat  = self.predict_mean(x)\n",
    "#         light = self.predict_FC1(feat)\n",
    "#         light = self.predict_relu1(light)\n",
    "#         light = self.predict_FC2(light)\n",
    "\n",
    "#         target_light = inputs[1]\n",
    "#         upFeat = self.post_FC1(target_light)\n",
    "#         upFeat = self.post_relu1(upFeat) #shared_axes solves bug in tf 1.13. not sure of side-effect.\n",
    "#         upFeat = self.post_FC2(upFeat)\n",
    "#         upFeat = self.post_relu2(upFeat)\n",
    "#         upFeat = self.post_tiler(upFeat)\n",
    "\n",
    "#         #x1 = self.slicer_x1(innerFeat)\n",
    "#         x2 = self.slicer_x2(innerFeat)\n",
    "#         #print(upFeat.shape, x2.shape)\n",
    "#         xout = Concatenate(axis=1)([upFeat, x2])\n",
    "#         return xout, light\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
